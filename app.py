import streamlit as st
import boto3
import json
import const
from PIL import Image
import traceback

def user_change():
    st.session_state.messages=[]

def init():
    st.set_page_config(page_title="ã‚†ã†ã²ã»ã‘ã‚“ãƒãƒ£ãƒƒãƒˆ", page_icon="â£ï¸")
    if "messages" not in st.session_state:
        st.session_state.messages=[]
        st.session_state.avater_icon=Image.open("avater.png")
    st.markdown(const.HIDE_ST_STYLE,unsafe_allow_html=True)
    st.session_state["knowledge_base_id"] = st.secrets["KNOWLEDGE_ID"]
    
    # å·¦ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.session_state["user_name"] = st.selectbox("å¥‘ç´„è€…ã‚’é¸æŠ",options=["ä¼Šè—¤ æ™ºä¹Ÿ","ç”°ä¸­ çœŸç¶¾","åŠ è—¤ å……","æ¾ç”° çµè¡£"],on_change=user_change)
        bedrock_model = st.selectbox("Bedrockã®ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„", (const.BEDROCK_MODEL_LIST))
        st.session_state["bedrock_model"] = bedrock_model
    
def main():
    st.markdown("<center><h1>ã‚†ã†ã²ã»ã‘ã‚“ãƒãƒ£ãƒƒãƒˆğŸŒ‡</h1></center>",unsafe_allow_html=True)

    with st.chat_message("Assistant",avatar=st.session_state["avater_icon"]):
        st.write(f"{st.session_state['user_name']}ã•ã‚“ã€ã“ã‚“ã«ã¡ã¯ï¼ä½•ã‹ãŠå›°ã‚Šã”ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ")
    for info in st.session_state.messages:
        with st.chat_message(info["role"]):
            st.write(info["content"])

    if prompt := st.chat_input(""):
        st.session_state.messages.append({"role": "Human", "content": prompt})
        with st.chat_message("Human"):
            st.markdown(prompt)
    
        with st.chat_message("Assistant",avatar=st.session_state["avater_icon"]):
            message_placeholder = st.empty()
            response = retrieve(prompt,message_placeholder)
                
        st.session_state.messages.append({"role": "Assistant", "content": response})

def invoke_model(message_placeholder, docs_input=""):
    bedrock = boto3.client(service_name="bedrock-runtime", region_name=const.REGION_NAME)
    messages = [message["role"] + ":" + message["content"] for message in st.session_state.messages]

    body = json.dumps(
        {
            "prompt": "system:"+const.SYSTEM_PROMPT.replace("%%user_name%%",st.session_state["user_name"])+ "infomations:"+docs_input+"\n\n" + "\n\n".join(messages) + "\n\nAssistant:",
            "max_tokens_to_sample":1000
        }
    )
    try:
        with st.spinner("ç¢ºèªä¸­..."):
            response = bedrock.invoke_model_with_response_stream(modelId=st.session_state["bedrock_model"], body=body)
        stream = response.get("body")
        full_response=""
        if stream:
            for event in stream:
                chunk = event.get("chunk")
                if chunk:
                    full_response += json.loads(chunk.get("bytes").decode("utf-8"))["completion"]
                    message_placeholder.markdown(full_response + "â–Œ")

            message_placeholder.write(full_response)
    except Exception as e:
        st.error("ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦ã‹ã‚‰å†åº¦ã”åˆ©ç”¨ãã ã•ã„ã€‚")
        print(e)
        print(list(traceback.TracebackException.from_exception(e).format()))
        st.stop()

    return full_response

def retrieve(input,message_placeholder):
    bedrock_agent_runtime = boto3.client("bedrock-agent-runtime", region_name=const.REGION_NAME)
    try:
        with st.spinner("ç¢ºèªä¸­..."):
            retrieve_response = bedrock_agent_runtime.retrieve(
            knowledgeBaseId= st.session_state["knowledge_base_id"],
            retrievalQuery={"text":input},
        )
    except Exception as e:
        st.error("ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦ã‹ã‚‰å†åº¦ã”åˆ©ç”¨ãã ã•ã„ã€‚")
        print(e)
        print(list(traceback.TracebackException.from_exception(e).format()))
        st.stop()

    full_response=invoke_model(message_placeholder,retrieve_response["retrievalResults"][0]["content"]["text"])

    return full_response


if __name__ == "__main__":
    init()
    main()